---
layout: default
---

[back](./)

## About

Hi, I'm Zach. I'm an early-stage researcher interested in interpretability, alignment, and control for AI systems.

### How I view the problem
Whether we like it or not, it's clear that AI will become increasingly prevalent as time goes on. **By default, this is a problem:**
1. We currently have very little understanding of how these systems work or how to control them.
    **Worst-case failure mode**: Existential risk from a misaligned superintelligence.
2. The amount of money and resources needed for frontier AI development implies that the most intelligent AI systems will likely be controlled by a small number of powerful actors / organizations.
    **Worst-case failure mode**: A dictator or oligarchy establish a permanently entrenched totalitarian regime.
While I don't think worst-case failure modes are the most likely outcomes, they demonstrate fundamental problems with the naive development of smarter-than-human AI. **By default**, we should expect disaster from technology that is significantly smarter than us, if it doesn't necessarily have the same goals as us.

### Personal info
I graduated from Georgia Tech in 2024 with an M.S. in Computer Science / Machine Learning, after completing my B.S. there was well.

I'm originally from Long Island, NY. In my free time, I like to read, engage in progressive politics,
and watch YouTube.

**Favorite movies**: Interstellar, Whiplash, Inglourious Basterds
**Favorite bands**: Red Hot Chili Peppers, Paramore, Greta Van Fleet

{:.center}
![image of me](/assets/images/profile-pic.jpg#center){:height="50%" width="50%" style="align: center;"}

